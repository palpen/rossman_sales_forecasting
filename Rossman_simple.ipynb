{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rossman_simple\n",
    "* Rossman competition without external data\n",
    "* See Lesson 12 of machine learning course for the full explanation of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from functions_and_modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN = '/Users/s6215054/Desktop/play/rossman_sales_forecasting'\n",
    "PATH = f'{MAIN}/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = ['train', 'store', 'test']\n",
    "tables = [pd.read_csv(f'{PATH}/{fname}.csv', low_memory=False) for fname in table_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>620.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
       "0      1         c          a               1270.0                        9.0   \n",
       "1      2         a          a                570.0                       11.0   \n",
       "2      3         a          a              14130.0                       12.0   \n",
       "3      4         c          c                620.0                        9.0   \n",
       "4      5         a          a              29910.0                        4.0   \n",
       "\n",
       "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
       "0                    2008.0       0              NaN              NaN   \n",
       "1                    2007.0       1             13.0           2010.0   \n",
       "2                    2006.0       1             14.0           2011.0   \n",
       "3                    2009.0       0              NaN              NaN   \n",
       "4                    2015.0       0              NaN              NaN   \n",
       "\n",
       "     PromoInterval  \n",
       "0              NaN  \n",
       "1  Jan,Apr,Jul,Oct  \n",
       "2  Jan,Apr,Jul,Oct  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning / Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1017209, 41088)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, store, test = tables\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode state holidays\n",
    "train.StateHoliday = train.StateHoliday!='0'\n",
    "test.StateHoliday = test.StateHoliday!='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add date features\n",
    "add_datepart(train, \"Date\", drop=False)\n",
    "add_datepart(test, \"Date\", drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>...</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Dayofyear</th>\n",
       "      <th>Is_month_end</th>\n",
       "      <th>Is_month_start</th>\n",
       "      <th>Is_quarter_end</th>\n",
       "      <th>Is_quarter_start</th>\n",
       "      <th>Is_year_end</th>\n",
       "      <th>Is_year_start</th>\n",
       "      <th>Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1442448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1442448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1442448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1442448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1442448000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Store  DayOfWeek       Date  Open  Promo  StateHoliday  SchoolHoliday  \\\n",
       "0   1      1          4 2015-09-17   1.0      1         False              0   \n",
       "1   2      3          4 2015-09-17   1.0      1         False              0   \n",
       "2   3      7          4 2015-09-17   1.0      1         False              0   \n",
       "3   4      8          4 2015-09-17   1.0      1         False              0   \n",
       "4   5      9          4 2015-09-17   1.0      1         False              0   \n",
       "\n",
       "   Year  Month     ...      Day  Dayofweek  Dayofyear  Is_month_end  \\\n",
       "0  2015      9     ...       17          3        260         False   \n",
       "1  2015      9     ...       17          3        260         False   \n",
       "2  2015      9     ...       17          3        260         False   \n",
       "3  2015      9     ...       17          3        260         False   \n",
       "4  2015      9     ...       17          3        260         False   \n",
       "\n",
       "   Is_month_start  Is_quarter_end  Is_quarter_start  Is_year_end  \\\n",
       "0           False           False             False        False   \n",
       "1           False           False             False        False   \n",
       "2           False           False             False        False   \n",
       "3           False           False             False        False   \n",
       "4           False           False             False        False   \n",
       "\n",
       "   Is_year_start     Elapsed  \n",
       "0          False  1442448000  \n",
       "1          False  1442448000  \n",
       "2          False  1442448000  \n",
       "3          False  1442448000  \n",
       "4          False  1442448000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joined = join_df(train, store, \"Store\")\n",
    "joined_test = join_df(test, store, \"Store\")\n",
    "display(len(joined[joined.StoreType.isnull()]),len(joined_test[joined_test.StoreType.isnull()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate columns due to merge\n",
    "for df in (joined, joined_test):\n",
    "    for c in df.columns:\n",
    "        if c.endswith('_y'):\n",
    "            if c in df.columns: df.drop(c, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (joined,joined_test):\n",
    "    df['CompetitionOpenSinceYear'] = df.CompetitionOpenSinceYear.fillna(1900).astype(np.int32)\n",
    "    df['CompetitionOpenSinceMonth'] = df.CompetitionOpenSinceMonth.fillna(1).astype(np.int32)\n",
    "    df['Promo2SinceYear'] = df.Promo2SinceYear.fillna(1900).astype(np.int32)\n",
    "    df['Promo2SinceWeek'] = df.Promo2SinceWeek.fillna(1).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit CompeitionOpen Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (joined, joined_test):\n",
    "    # Convert CompetitionOpenSinceMonth and CompetitionOpenSinceYear\n",
    "    # features to a proper datetime object\n",
    "    comp_dict = dict(year=df.CompetitionOpenSinceYear, \n",
    "                     month=df.CompetitionOpenSinceMonth, \n",
    "                     day=15)\n",
    "    df[\"CompetitionOpenSince\"] = pd.to_datetime(comp_dict)\n",
    "\n",
    "    # Create feature on # of days since competition opened\n",
    "    df[\"CompetitionDaysOpen\"] = (df.\n",
    "                                 Date.\n",
    "                                 subtract(df.CompetitionOpenSince).\n",
    "                                 dt.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If CompeitionDaysOpen is negative or occured in year before 1990\n",
    "# just set it equal to zero\n",
    "for df in (joined,joined_test):\n",
    "    df.loc[df.CompetitionDaysOpen<0, \"CompetitionDaysOpen\"] = 0\n",
    "    df.loc[df.CompetitionOpenSinceYear<1990, \"CompetitionDaysOpen\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature on # of months since compeition open\n",
    "# If number of months is greater than 24 (i.e. > 2 years open)\n",
    "# top code it and set to 24 months\n",
    "for df in (joined,joined_test):\n",
    "    \n",
    "    df[\"CompetitionMonthsOpen\"] = df[\"CompetitionDaysOpen\"] // 30\n",
    "\n",
    "    df.loc[df.CompetitionMonthsOpen>24, \"CompetitionMonthsOpen\"] = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit Promo Feature\n",
    "Apply same approach to Promo feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (joined,joined_test):\n",
    "    # Convert Promo2SinceWeek and Promo2SinceYear into\n",
    "    # a proper datetime object\n",
    "    df[\"Promo2Since\"] = pd.to_datetime(df.apply(lambda x: Week(\n",
    "        x.Promo2SinceYear, x.Promo2SinceWeek).monday(), axis=1).astype(pd.datetime))\n",
    "    \n",
    "    # Compute number of days since last Promo2 was first introduced\n",
    "    df[\"Promo2Days\"] = df.Date.subtract(df[\"Promo2Since\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (joined,joined_test):\n",
    "    \n",
    "    # If days since is negative or before 1990, set to 0\n",
    "    df.loc[df.Promo2Days<0, \"Promo2Days\"] = 0\n",
    "    df.loc[df.Promo2SinceYear<1990, \"Promo2Days\"] = 0\n",
    "    \n",
    "    # Number of weeks\n",
    "    df[\"Promo2Weeks\"] = df[\"Promo2Days\"]//7\n",
    "\n",
    "    # If continuous promo is older than 25 weeks, top code to 25 weeks\n",
    "    df.loc[df.Promo2Weeks<0, \"Promo2Weeks\"] = 0\n",
    "    df.loc[df.Promo2Weeks>25, \"Promo2Weeks\"] = 25\n",
    "    df.Promo2Weeks.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featherize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.to_feather(f'{PATH}/joined_simple')\n",
    "joined_test.to_feather(f'{PATH}/joined_test_simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durations Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = feather.read_dataframe(f'{PATH}/joined_simple')\n",
    "joined_test = feather.read_dataframe(f'{PATH}/joined_test_simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periods elapsed\n",
    "* Period elapsed computes the # of days before a holiday takes place and the # of days since the last holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns on which we will apply get_elapsed\n",
    "columns = [\"Date\", \"Store\", \"Promo\", \"StateHoliday\", \"SchoolHoliday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append rows in test[columns] to end of train[columns]\n",
    "# Why?\n",
    "# Periods elapsed need dates from training in order for \n",
    "# window to roll continuously\n",
    "df = train[columns].append(test[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SchoolHoliday get elapsed...\n",
      "StateHoliday get elapsed...\n",
      "Promo get elapsed...\n"
     ]
    }
   ],
   "source": [
    "# Get time elapsed before and after event (see explanation below)\n",
    "\n",
    "print(\"SchoolHoliday get elapsed...\")\n",
    "fld = 'SchoolHoliday'\n",
    "\n",
    "df = df.sort_values(['Store', 'Date'])\n",
    "CompFuncs.get_elapsed(df, fld, 'After')\n",
    "\n",
    "df = df.sort_values(['Store', 'Date'], ascending=[True, False])\n",
    "CompFuncs.get_elapsed(df, fld, 'Before')\n",
    "\n",
    "print(\"StateHoliday get elapsed...\")\n",
    "fld = 'StateHoliday'\n",
    "df = df.sort_values(['Store', 'Date'])\n",
    "CompFuncs.get_elapsed(df, fld, 'After')\n",
    "df = df.sort_values(['Store', 'Date'], ascending=[True, False])\n",
    "CompFuncs.get_elapsed(df, fld, 'Before')\n",
    "\n",
    "print(\"Promo get elapsed...\")\n",
    "fld = 'Promo'\n",
    "df = df.sort_values(['Store', 'Date'])\n",
    "CompFuncs.get_elapsed(df, fld, 'After')\n",
    "df = df.sort_values(['Store', 'Date'], ascending=[True, False])\n",
    "CompFuncs.get_elapsed(df, fld, 'Before')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1017209, 22), (41088, 21), (1058297, 11))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"Date\")\n",
    "columns = ['SchoolHoliday', 'StateHoliday', 'Promo']\n",
    "\n",
    "for o in ['Before', 'After']:\n",
    "    for p in columns:\n",
    "        a = o+p\n",
    "        df[a] = df[a].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling quantities\n",
    "* Compute the forward and backward window rolling sum\n",
    "* For a given row, bwd computes the sum total of days a holiday has been in effect in the past 7 days\n",
    "* Similarly, for a given row, fwd computes the the sum total of days before a holiday ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back of rolling window\n",
    "bwd = (\n",
    "        df[['Store']+columns].\n",
    "        sort_index().\n",
    "        groupby(\"Store\").\n",
    "        rolling(7, min_periods=1).\n",
    "        sum()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front of rolling window\n",
    "fwd = (\n",
    "        df[['Store']+columns].\n",
    "        sort_index(ascending=False).\n",
    "        groupby(\"Store\").\n",
    "        rolling(7, min_periods=1).\n",
    "        sum()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd.drop('Store',1,inplace=True)\n",
    "bwd.reset_index(inplace=True)\n",
    "fwd.drop('Store',1,inplace=True)\n",
    "fwd.reset_index(inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all together\n",
    "df = df.merge(bwd, 'left', ['Date', 'Store'], suffixes=['', '_bw'])\n",
    "df = df.merge(fwd, 'left', ['Date', 'Store'], suffixes=['', '_fw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original columns\n",
    "df.drop(columns,1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding intuition for periods elapsed and rolling quantities  features\n",
    "# Comment out drop of orig. columns in previous cell to see original columns\n",
    "\n",
    "# school_cols = ['Date',\n",
    "#  'Store',\n",
    "#  'SchoolHoliday_bw',\n",
    "#  'SchoolHoliday',\n",
    "#  'SchoolHoliday_fw']\n",
    "\n",
    "# school_cols = ['Date',\n",
    "#  'Store',\n",
    "#  'AfterSchoolHoliday',\n",
    "#  'SchoolHoliday',\n",
    "#  'BeforeSchoolHoliday']\n",
    "\n",
    "# df[school_cols].sort_values(['Store', 'Date'], ascending=[True, False]).head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join back with joined df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = join_df(joined, df, ['Store', 'Date'])\n",
    "joined_test = join_df(joined_test, df, ['Store', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restricting to cases where sales are positive\n",
    "joined = joined[joined.Sales!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featherize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feather Save\n",
    "joined.reset_index().to_feather(f'{PATH}/joined')\n",
    "joined_test.reset_index().to_feather(f'{PATH}/joined_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feather Load\n",
    "joined = feather.read_dataframe(f'{PATH}/joined')\n",
    "joined_test = feather.read_dataframe(f'{PATH}/joined_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = [\n",
    "    'Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen',\n",
    "    'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear',\n",
    "    'Week', 'Promo_fw', 'Promo_bw', 'StateHoliday_fw', 'StateHoliday_bw',\n",
    "    'SchoolHoliday_fw', 'SchoolHoliday_bw'\n",
    "]\n",
    "contin_vars = ['CompetitionDistance', 'AfterStateHoliday', \n",
    "               'BeforeStateHoliday', 'Promo', 'SchoolHoliday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep = 'Sales'\n",
    "joined = joined[cat_vars + contin_vars + [dep, 'Date']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_test[dep] = 0\n",
    "joined_test = joined_test[cat_vars + contin_vars + [dep, 'Date', 'Id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast var as a category dtype\n",
    "for v in cat_vars:\n",
    "     joined[v] = joined[v].astype('category').cat.as_ordered()\n",
    "\n",
    "# Make categorical encoding in joined_test to be\n",
    "# the same as in joined\n",
    "# If Saturday in a week category feature is encoded as a 6\n",
    "# in the training set, it will be a 6 in the test set\n",
    "apply_cats(joined_test, joined)\n",
    "\n",
    "# For each continuous var, fill mising with 0 and\n",
    "# cast as float32 (requirement by Pytorch)\n",
    "for v in contin_vars:\n",
    "    joined[v] = joined[v].fillna(0).astype('float32')\n",
    "    joined_test[v] = joined_test[v].fillna(0).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featherize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feather Save\n",
    "# joined.reset_index().to_feather(f'{PATH}/joined')\n",
    "# joined_test.reset_index().to_feather(f'{PATH}/joined_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and Final Data Prep\n",
    "* Scaling important for neural networks\n",
    "* `mapper` keeps track of mean, median used in normalization for application to test set\n",
    "* `nas` keeps track of missing (cat: missing become zero, continuous: missing becomes median and creates new boolean column if col missing in row)\n",
    "* See ML course for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feather Load\n",
    "# joined = feather.read_dataframe(f'{PATH}/joined')\n",
    "# joined_test = feather.read_dataframe(f'{PATH}/joined_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!!\n",
    "\n",
    "n = len(joined)\n",
    "\n",
    "# Get sub-sample of data\n",
    "idxs = get_cv_idxs(n, val_pct=150000/n)  # ???\n",
    "joined_samp = joined.iloc[idxs].set_index(\"Date\")\n",
    "samp_size = len(joined_samp); samp_size\n",
    "\n",
    "# To run on the full dataset, use this instead:\n",
    "# samp_size = n\n",
    "# joined_samp = joined.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off the response variable, convert to all columns to\n",
    "# numeric. Particularly the categorical vars\n",
    "df, y, nas, mapper = proc_df(joined_samp, 'Sales', \n",
    "                             do_scale=True)\n",
    "yl = np.log(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mapper object contains the column names and the corresponding transformation applied to them (such as the StandardScaler for continuous variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_test = joined_test.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do same to test sample\n",
    "# Note application of nas and mapper derived from training\n",
    "# to ensure treatment of missing is same as in training set\n",
    "df_test, _, nas, mapper = proc_df(joined_test, 'Sales', \n",
    "                                  do_scale=True, skip_flds=['Id'],\n",
    "                                  mapper=mapper, na_dict=nas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `cond` below is an array containing booleans that is true if the\n",
    "element in df.index satisfies the condition\n",
    "* `np.flatnonzero` returns an array of indices where the corresponding\n",
    "element in cond is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index for data to be used for validation\n",
    "# Last two weeks of training set\n",
    "\n",
    "# Number of data used in validation == number of data in test set\n",
    "# which is from 2014,8,1 to 2014,9,17\n",
    "\n",
    "# val_idx contains the index for which the date in df.index\n",
    "# is in between 2014/8/1 and 2014/9/17\n",
    "\n",
    "# Note the year for validation. In the test data, the corresponding\n",
    "# interval is 2015-08-01 to 2015-09-17\n",
    "\n",
    "# We are using only the 2014 data hare\n",
    "cond = (df.index >= datetime.datetime(2014,8,1)) & \\\n",
    "       (df.index <= datetime.datetime(2014,9,17)) \n",
    "\n",
    "val_idx = np.flatnonzero(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See ML video, lesson 12 00:30:00 mark\n",
    "# This is for full training on the entire dataset\n",
    "# for the final model\n",
    "\n",
    "# Do this after settling on a given model and hyperparameters\n",
    "\n",
    "# val_idx = [0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "* oob_score: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split validation / training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "((val,trn), (y_val,y_trn)) = split_by_idx(val_idx, df.values, yl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9350441970942147, 0.842723494322492, 0.16456469688910202)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators'=40, \n",
    "    'max_features'=0.33, \n",
    "    'min_samples_leaf'=2,\n",
    "    'n_jobs'=-1, \n",
    "    'oob_score'=False\n",
    "}\n",
    "m = RandomForestRegressor(**params)\n",
    "m.fit(trn, y_trn)\n",
    "preds = m.predict(val)\n",
    "m.score(trn, y_trn), m.score(val, y_val), CompFuncs.exp_rmspe(preds, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9676962609517541, 0.9105141238751029, 0.12250462415303369)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators'=40, \n",
    "    'max_features'=0.99, \n",
    "    'min_samples_leaf'=2,\n",
    "    'n_jobs'=-1, \n",
    "    'oob_score'=False\n",
    "}\n",
    "m = RandomForestRegressor(**params)\n",
    "m.fit(trn, y_trn);\n",
    "preds = m.predict(val)\n",
    "m.score(trn, y_trn), m.score(val, y_val), CompFuncs.exp_rmspe(preds, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"n_estimators\": 300,\n",
    "          \"max_depth\": 8,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"subsample\": 0.7\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.926170871417617, 0.8983104735215454, 0.13236952552405945)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = XGBRegressor(**params)\n",
    "m.fit(trn, y_trn)\n",
    "preds = m.predict(val)\n",
    "m.score(trn, y_trn), m.score(val, y_val), CompFuncs.exp_rmspe(preds, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
